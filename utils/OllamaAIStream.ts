// utils/OllamaAIStream.ts
import { ChatOllama } from "@langchain/community/chat_models/ollama";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { z } from "zod";

// üîí –°—Ö–µ–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
const RequestSchema = z.object({
  messages: z.array(z.object({
    role: z.enum(["user", "system", "assistant"]),
    content: z.string()
  })),
  stream: z.boolean().optional().default(false)
});

// üöÄ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Ollama
export const OLLAMA_CONFIG = {
  baseUrl: process.env.OLLAMA_URL || "http://localhost:11434",
  model: process.env.OLLAMA_MODEL || "llama3.1",
  temperature: 0.7,
  maxTokens: 1024
};

export async function OllamaAIStream(request: Request) {
  const encoder = new TextEncoder();

  try {
    // 1. –ü–∞—Ä—Å–∏–Ω–≥ payload
    const payload = await request.json();
    const { messages, stream } = RequestSchema.parse(payload);

    // 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    const chatModel = new ChatOllama({
      baseUrl: OLLAMA_CONFIG.baseUrl,
      model: OLLAMA_CONFIG.model,
      temperature: OLLAMA_CONFIG.temperature
    });

    // 3. –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏
    const prompt = ChatPromptTemplate.fromMessages(messages);
    const chain = prompt.pipe(chatModel).pipe(new StringOutputParser());

    // 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
    if (stream) {
      const readableStream = new ReadableStream({
        async start(controller) {
          try {
            const response = await chain.stream({});

            for await (const chunk of response) {
              const payload = { text: chunk };
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify(payload)}\n\n`)
              );
            }

            controller.close();
          } catch (error) {
            controller.error(error);
          }
        }
      });

      return new Response(readableStream, {
        headers: {
          "Content-Type": "text/event-stream",
          "Cache-Control": "no-store"
        }
      });
    } else {
      // –û–±—ã—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–µ–∑ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
      const response = await chain.invoke({});

      return new Response(response, {
        headers: {
          "Content-Type": "text/plain",
          "Cache-Control": "no-store"
        }
      });
    }

  } catch (error) {
    console.error("üî• –û—à–∏–±–∫–∞ –≤ OllamaAIStream:", error);

    // –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
    if (error instanceof z.ZodError) {
      return new Response(JSON.stringify({
        error: "–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
        details: error.errors
      }), {
        status: 400,
        headers: { "Content-Type": "application/json" }
      });
    }

    return new Response("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞", {
      status: 500,
      headers: { "Content-Type": "text/plain" }
    });
  }
}
